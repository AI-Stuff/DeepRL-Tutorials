{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q Network with Noisy Networks for Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import math\n",
    "\n",
    "from utils.wrappers import *\n",
    "from utils.ReplayMemory import PrioritizedReplayMemory\n",
    "from networks.layers import NoisyLinear\n",
    "from agents.DQN import Model as DQN_Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Multi-step returns\n",
    "N_STEPS = 3\n",
    "\n",
    "#misc agent variables\n",
    "GAMMA=0.99\n",
    "LR=1e-4\n",
    "\n",
    "#memory\n",
    "TARGET_NET_UPDATE_FREQ = 1000\n",
    "EXP_REPLAY_SIZE = 100000\n",
    "BATCH_SIZE = 32\n",
    "PRIORITY_ALPHA=0.6\n",
    "PRIORITY_BETA_START=0.4\n",
    "PRIORITY_BETA_FRAMES = 100000\n",
    "\n",
    "#epsilon variables\n",
    "SIGMA_INIT=0.5\n",
    "\n",
    "#Learning control variables\n",
    "LEARN_START = 10000\n",
    "MAX_FRAMES=700000\n",
    "\n",
    "#Categorical Params\n",
    "ATOMS = 51\n",
    "V_MAX = 10\n",
    "V_MIN = -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalDuelingDQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions, sigma_init=0.5, atoms=51):\n",
    "        super(CategoricalDuelingDQN, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.num_actions = num_actions\n",
    "        self.atoms = atoms\n",
    "\n",
    "        self.conv1 = nn.Conv2d(self.input_shape[0], 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "\n",
    "        self.adv1 = NoisyLinear(self.feature_size(), 512, sigma_init)\n",
    "        self.adv2 = NoisyLinear(512, self.num_actions*self.atoms, sigma_init)\n",
    "\n",
    "        self.val1 = NoisyLinear(self.feature_size(), 512, sigma_init)\n",
    "        self.val2 = NoisyLinear(512, 1*self.atoms, sigma_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        adv = F.relu(self.adv1(x))\n",
    "        adv = self.adv2(adv).view(-1, self.num_actions, self.atoms)\n",
    "\n",
    "        val = F.relu(self.val1(x))\n",
    "        val = self.val2(val).view(-1, 1, self.atoms)\n",
    "\n",
    "        final = val + adv - adv.mean(dim=1).view(-1, 1, self.atoms)\n",
    "\n",
    "        return F.softmax(final, dim=2)\n",
    "    \n",
    "    def feature_size(self):\n",
    "        return self.conv3(self.conv2(self.conv1(torch.zeros(1, *self.input_shape)))).view(1, -1).size(1)\n",
    "\n",
    "    def sample_noise(self):\n",
    "        self.adv1.sample_noise()\n",
    "        self.adv2.sample_noise()\n",
    "        self.val1.sample_noise()\n",
    "        self.val2.sample_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(DQN_Agent):\n",
    "    def __init__(self, static_policy=False, env=None):\n",
    "        self.gamma=GAMMA\n",
    "        self.lr = LR\n",
    "        self.target_net_update_freq = TARGET_NET_UPDATE_FREQ\n",
    "        self.experience_replay_size = EXP_REPLAY_SIZE\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.learn_start = LEARN_START\n",
    "        self.sigma_init=SIGMA_INIT\n",
    "        self.priority_beta_start = PRIORITY_BETA_START\n",
    "        self.priority_beta_frames = PRIORITY_BETA_FRAMES\n",
    "        self.priority_alpha = PRIORITY_ALPHA\n",
    "        self.atoms=ATOMS\n",
    "        self.v_max=V_MAX\n",
    "        self.v_min=V_MIN\n",
    "        self.supports = torch.linspace(self.v_min, self.v_max, self.atoms).view(1, 1, self.atoms).to(device)\n",
    "        self.delta = (self.v_max - self.v_min) / (self.atoms - 1)\n",
    "\n",
    "        self.static_policy=static_policy\n",
    "        self.num_feats = env.observation_space.shape\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.env = env\n",
    "\n",
    "        self.declare_networks()\n",
    "            \n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        #move to correct device\n",
    "        self.model = self.model.to(device)\n",
    "        self.target_model.to(device)\n",
    "\n",
    "        if self.static_policy:\n",
    "            self.model.eval()\n",
    "            self.target_model.eval()\n",
    "        else:\n",
    "            self.model.train()\n",
    "            self.target_model.train()\n",
    "\n",
    "        self.update_count = 0\n",
    "\n",
    "        self.declare_memory()\n",
    "\n",
    "        self.nsteps = N_STEPS\n",
    "        self.nstep_buffer = []\n",
    "    \n",
    "    def declare_networks(self):\n",
    "        self.model = CategoricalDuelingDQN(self.num_feats, self.num_actions, sigma_init=self.sigma_init, atoms=self.atoms)\n",
    "        self.target_model = CategoricalDuelingDQN(self.num_feats, self.num_actions, sigma_init=self.sigma_init, atoms=self.atoms)\n",
    "        \n",
    "    def declare_memory(self):\n",
    "        self.memory = PrioritizedReplayMemory(self.experience_replay_size, self.priority_alpha, self.priority_beta_start, self.priority_beta_frames)\n",
    "        \n",
    "    def projection_distribution(self, batch_vars):\n",
    "        batch_state, batch_action, batch_reward, non_final_next_states, non_final_mask, empty_next_state_values, indices, weights = batch_vars\n",
    "\n",
    "        with torch.no_grad():\n",
    "            max_next_dist = torch.zeros((self.batch_size, 1, self.atoms), device=device, dtype=torch.float) + 1./self.atoms\n",
    "            if not empty_next_state_values:\n",
    "                max_next_action = self.get_max_next_state_action(non_final_next_states)\n",
    "                self.target_model.sample_noise()\n",
    "                max_next_dist[non_final_mask] = self.target_model(non_final_next_states).gather(1, max_next_action)\n",
    "                max_next_dist = max_next_dist.squeeze()\n",
    "\n",
    "\n",
    "            Tz = batch_reward.view(-1, 1) + (self.gamma**self.nsteps)*self.supports.view(1, -1) * non_final_mask.to(torch.float).view(-1, 1)\n",
    "            Tz = Tz.clamp(self.v_min, self.v_max)\n",
    "            b = (Tz - self.v_min) / self.delta\n",
    "            l = b.floor().to(torch.int64)\n",
    "            u = b.ceil().to(torch.int64)\n",
    "            l[(u > 0) * (l == u)] -= 1\n",
    "            u[(l < (self.atoms - 1)) * (l == u)] += 1\n",
    "            \n",
    "\n",
    "            offset = torch.linspace(0, (self.batch_size - 1) * self.atoms, self.batch_size).unsqueeze(dim=1).expand(self.batch_size, self.atoms).to(batch_action)\n",
    "            m = batch_state.new_zeros(self.batch_size, self.atoms)\n",
    "            m.view(-1).index_add_(0, (l + offset).view(-1), (max_next_dist * (u.float() - b)).view(-1))  # m_l = m_l + p(s_t+n, a*)(u - b)\n",
    "            m.view(-1).index_add_(0, (u + offset).view(-1), (max_next_dist * (b - l.float())).view(-1))  # m_u = m_u + p(s_t+n, a*)(b - l)\n",
    "\n",
    "        return m\n",
    "    \n",
    "    def compute_loss(self, batch_vars):\n",
    "        batch_state, batch_action, batch_reward, non_final_next_states, non_final_mask, empty_next_state_values, indices, weights = batch_vars\n",
    "\n",
    "        batch_action = batch_action.unsqueeze(dim=-1).expand(-1, -1, self.atoms)\n",
    "        batch_reward = batch_reward.view(-1, 1, 1)\n",
    "\n",
    "        #estimate\n",
    "        self.model.sample_noise()\n",
    "        current_dist = self.model(batch_state).gather(1, batch_action).squeeze()\n",
    "\n",
    "        target_prob = self.projection_distribution(batch_vars)\n",
    "          \n",
    "        loss = -(target_prob * current_dist.log()).sum(-1)\n",
    "        self.memory.update_priorities(indices, loss.detach().squeeze().abs().cpu().numpy().tolist())\n",
    "        loss = loss * weights\n",
    "        loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def get_action(self, s):\n",
    "        with torch.no_grad():\n",
    "            X = torch.tensor([s], device=device, dtype=torch.float)\n",
    "            self.model.sample_noise()\n",
    "            a = self.model(X) * self.supports\n",
    "            a = a.sum(dim=2).max(1)[1].view(1, 1)\n",
    "            return a.item()\n",
    "            \n",
    "    def get_max_next_state_action(self, next_states):\n",
    "        next_dist = self.model(next_states) * self.supports\n",
    "        return next_dist.sum(dim=2).max(1)[1].view(next_states.size(0), 1, 1).expand(-1, -1, self.atoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards, losses, elapsed_time):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s. time: %s' % (frame_idx, np.mean(rewards[-10:]), elapsed_time))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 4: length of src.size[dim] is not equal to length of indices at /pytorch/aten/src/THC/generic/THCTensorIndex.cu:30",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-96ebddf2f1ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/git_repos/DeepRL-Tutorials/agents/DQN.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, s, a, r, s_, frame)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mbatch_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# Optimize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7d519cf1eebd>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, batch_vars)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mcurrent_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mtarget_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_prob\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcurrent_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7d519cf1eebd>\u001b[0m in \u001b[0;36mprojection_distribution\u001b[0;34m(self, batch_vars)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matoms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matoms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matoms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_next_dist\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# m_l = m_l + p(s_t+n, a*)(u - b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_next_dist\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# m_u = m_u + p(s_t+n, a*)(b - l)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 4: length of src.size[dim] is not equal to length of indices at /pytorch/aten/src/THC/generic/THCTensorIndex.cu:30"
     ]
    }
   ],
   "source": [
    "start=timer()\n",
    "\n",
    "env_id = \"PongNoFrameskip-v4\"\n",
    "env    = make_atari(env_id)\n",
    "env    = wrap_deepmind(env, frame_stack=True)\n",
    "env    = wrap_pytorch(env)\n",
    "model = Model(env=env)\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "observation = env.reset()\n",
    "for frame_idx in range(1, MAX_FRAMES + 1):\n",
    "    action = model.get_action(observation)\n",
    "    prev_observation=observation\n",
    "    observation, reward, done, _ = env.step(action)\n",
    "    observation = None if done else observation\n",
    "\n",
    "    loss = model.update(prev_observation, action, reward, observation, frame_idx)\n",
    "    episode_reward += reward\n",
    "\n",
    "    if done:\n",
    "        model.finish_nstep()\n",
    "        observation = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "        \n",
    "        if np.mean(all_rewards[-10:]) > 19:\n",
    "            plot(frame_idx, all_rewards, losses, timedelta(seconds=int(timer()-start)))\n",
    "            break\n",
    "\n",
    "    if loss is not None:\n",
    "        losses.append(loss)\n",
    "\n",
    "    if frame_idx % 10000 == 0:\n",
    "            plot(frame_idx, all_rewards, losses, timedelta(seconds=int(timer()-start)))\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
